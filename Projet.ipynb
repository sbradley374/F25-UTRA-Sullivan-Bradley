{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2,os,shutil,glob\n",
    "import DPT.util.io as util\n",
    "import DPT.run_monodepth as depth\n",
    "import DPT.run_segmentation as seg\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs = glob.glob('datasets/inria/frames/*/*.jpg')\n",
    "# imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = cv2.imread(imgs[0])\n",
    "# i = cv2.cvtColor(i, cv2.COLOR_BGR2RGB)\n",
    "# plt.imshow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(cv2.imread('DPT/output_monodepth/00012248.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img,_ = util.read_pfm(\"DPT/output_monodepth/00012248.pfm\")\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#human palette: (class 13) adepallete[13*3:14*3]\n",
    "#150 5 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize\n",
      "device: cuda\n",
      "start processing\n",
      "  processing datasets/train/inputs\\0.jpg (1/100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\antoine cadiou\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  processing datasets/train/inputs\\1.jpg (2/100)\n",
      "  processing datasets/train/inputs\\10.jpg (3/100)\n",
      "  processing datasets/train/inputs\\11.jpg (4/100)\n",
      "  processing datasets/train/inputs\\12.jpg (5/100)\n",
      "  processing datasets/train/inputs\\13.jpg (6/100)\n",
      "  processing datasets/train/inputs\\14.jpg (7/100)\n",
      "  processing datasets/train/inputs\\15.jpg (8/100)\n",
      "  processing datasets/train/inputs\\16.jpg (9/100)\n",
      "  processing datasets/train/inputs\\17.jpg (10/100)\n",
      "  processing datasets/train/inputs\\18.jpg (11/100)\n",
      "  processing datasets/train/inputs\\19.jpg (12/100)\n",
      "  processing datasets/train/inputs\\2.jpg (13/100)\n",
      "  processing datasets/train/inputs\\20.jpg (14/100)\n",
      "  processing datasets/train/inputs\\21.jpg (15/100)\n",
      "  processing datasets/train/inputs\\22.jpg (16/100)\n",
      "  processing datasets/train/inputs\\23.jpg (17/100)\n",
      "  processing datasets/train/inputs\\24.jpg (18/100)\n",
      "  processing datasets/train/inputs\\25.jpg (19/100)\n",
      "  processing datasets/train/inputs\\26.jpg (20/100)\n",
      "  processing datasets/train/inputs\\27.jpg (21/100)\n",
      "  processing datasets/train/inputs\\28.jpg (22/100)\n",
      "  processing datasets/train/inputs\\29.jpg (23/100)\n",
      "  processing datasets/train/inputs\\3.jpg (24/100)\n",
      "  processing datasets/train/inputs\\30.jpg (25/100)\n",
      "  processing datasets/train/inputs\\31.jpg (26/100)\n",
      "  processing datasets/train/inputs\\32.jpg (27/100)\n",
      "  processing datasets/train/inputs\\33.jpg (28/100)\n",
      "  processing datasets/train/inputs\\34.jpg (29/100)\n",
      "  processing datasets/train/inputs\\35.jpg (30/100)\n",
      "  processing datasets/train/inputs\\36.jpg (31/100)\n",
      "  processing datasets/train/inputs\\37.jpg (32/100)\n",
      "  processing datasets/train/inputs\\38.jpg (33/100)\n",
      "  processing datasets/train/inputs\\39.jpg (34/100)\n",
      "  processing datasets/train/inputs\\4.jpg (35/100)\n",
      "  processing datasets/train/inputs\\40.jpg (36/100)\n",
      "  processing datasets/train/inputs\\41.jpg (37/100)\n",
      "  processing datasets/train/inputs\\42.jpg (38/100)\n",
      "  processing datasets/train/inputs\\43.jpg (39/100)\n",
      "  processing datasets/train/inputs\\44.jpg (40/100)\n",
      "  processing datasets/train/inputs\\45.jpg (41/100)\n",
      "  processing datasets/train/inputs\\46.jpg (42/100)\n",
      "  processing datasets/train/inputs\\47.jpg (43/100)\n",
      "  processing datasets/train/inputs\\48.jpg (44/100)\n",
      "  processing datasets/train/inputs\\49.jpg (45/100)\n",
      "  processing datasets/train/inputs\\5.jpg (46/100)\n",
      "  processing datasets/train/inputs\\50.jpg (47/100)\n",
      "  processing datasets/train/inputs\\51.jpg (48/100)\n",
      "  processing datasets/train/inputs\\52.jpg (49/100)\n",
      "  processing datasets/train/inputs\\53.jpg (50/100)\n",
      "  processing datasets/train/inputs\\54.jpg (51/100)\n",
      "  processing datasets/train/inputs\\55.jpg (52/100)\n",
      "  processing datasets/train/inputs\\56.jpg (53/100)\n",
      "  processing datasets/train/inputs\\57.jpg (54/100)\n",
      "  processing datasets/train/inputs\\58.jpg (55/100)\n",
      "  processing datasets/train/inputs\\59.jpg (56/100)\n",
      "  processing datasets/train/inputs\\6.jpg (57/100)\n",
      "  processing datasets/train/inputs\\60.jpg (58/100)\n",
      "  processing datasets/train/inputs\\61.jpg (59/100)\n",
      "  processing datasets/train/inputs\\62.jpg (60/100)\n",
      "  processing datasets/train/inputs\\63.jpg (61/100)\n",
      "  processing datasets/train/inputs\\64.jpg (62/100)\n",
      "  processing datasets/train/inputs\\65.jpg (63/100)\n",
      "  processing datasets/train/inputs\\66.jpg (64/100)\n",
      "  processing datasets/train/inputs\\67.jpg (65/100)\n",
      "  processing datasets/train/inputs\\68.jpg (66/100)\n",
      "  processing datasets/train/inputs\\69.jpg (67/100)\n",
      "  processing datasets/train/inputs\\7.jpg (68/100)\n",
      "  processing datasets/train/inputs\\70.jpg (69/100)\n",
      "  processing datasets/train/inputs\\71.jpg (70/100)\n",
      "  processing datasets/train/inputs\\72.jpg (71/100)\n",
      "  processing datasets/train/inputs\\73.jpg (72/100)\n",
      "  processing datasets/train/inputs\\74.jpg (73/100)\n",
      "  processing datasets/train/inputs\\75.jpg (74/100)\n",
      "  processing datasets/train/inputs\\76.jpg (75/100)\n",
      "  processing datasets/train/inputs\\77.jpg (76/100)\n",
      "  processing datasets/train/inputs\\78.jpg (77/100)\n",
      "  processing datasets/train/inputs\\79.jpg (78/100)\n",
      "  processing datasets/train/inputs\\8.jpg (79/100)\n",
      "  processing datasets/train/inputs\\80.jpg (80/100)\n",
      "  processing datasets/train/inputs\\81.jpg (81/100)\n",
      "  processing datasets/train/inputs\\82.jpg (82/100)\n",
      "  processing datasets/train/inputs\\83.jpg (83/100)\n",
      "  processing datasets/train/inputs\\84.jpg (84/100)\n",
      "  processing datasets/train/inputs\\85.jpg (85/100)\n",
      "  processing datasets/train/inputs\\86.jpg (86/100)\n",
      "  processing datasets/train/inputs\\87.jpg (87/100)\n",
      "  processing datasets/train/inputs\\88.jpg (88/100)\n",
      "  processing datasets/train/inputs\\89.jpg (89/100)\n",
      "  processing datasets/train/inputs\\9.jpg (90/100)\n",
      "  processing datasets/train/inputs\\90.jpg (91/100)\n",
      "  processing datasets/train/inputs\\91.jpg (92/100)\n",
      "  processing datasets/train/inputs\\92.jpg (93/100)\n",
      "  processing datasets/train/inputs\\93.jpg (94/100)\n",
      "  processing datasets/train/inputs\\94.jpg (95/100)\n",
      "  processing datasets/train/inputs\\95.jpg (96/100)\n",
      "  processing datasets/train/inputs\\96.jpg (97/100)\n",
      "  processing datasets/train/inputs\\97.jpg (98/100)\n",
      "  processing datasets/train/inputs\\98.jpg (99/100)\n",
      "  processing datasets/train/inputs\\99.jpg (100/100)\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "# for i,e in enumerate(np.random.choice(imgs, 100)):\n",
    "#     shutil.copy(e, \"datasets/train/inputs/\"+str(i)+\".jpg\")\n",
    "\n",
    "depth.run('datasets/train/inputs/', \\\n",
    "          'datasets/train/outputs/', \\\n",
    "          'DPT/weights/dpt_large-midas-2f21e586.pt', \\\n",
    "          model_type=\"dpt_large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for e in tqdm(os.listdir('datasets/inria/frames/')):\n",
    "#     depth.run('datasets/inria/frames/'+e+\"/\", \\\n",
    "#               'datasets/inria/depths/'+e+\"/\", \\\n",
    "#               'DPT/weights/dpt_large-midas-2f21e586.pt', \\\n",
    "#               model_type=\"dpt_large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seg.run('datasets/inria/frames/7/', \\\n",
    "#           'datasets/inria/seg/7/', \\\n",
    "#           'DPT/weights/dpt_large-ade20k-b12dca68.pt', \\\n",
    "#           model_type=\"dpt_large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
